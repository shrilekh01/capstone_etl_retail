

```markdown
# ğŸ“˜ Retail ETL Platform

## ğŸ“Œ Project Overview

This project is an **end-to-end ETL (Extract, Transform, Load) pipeline** built using **Python and MySQL**, designed to simulate a **real-world data warehouse ingestion system**.

It demonstrates:
- Incremental data loading
- Audit logging
- Data validation
- Layer-wise testing using Pytest
- Production-style ETL architecture
- Clean Git workflow

This project is suitable for **ETL / Data Engineer / Data QA roles**.

---

## ğŸ—ï¸ High-Level Architecture

```

Source Tables (MySQL)
â”‚
â–¼
Staging Layer
â”‚
â–¼
Transformation Layer
â”‚
â–¼
Fact Tables
â”‚
â–¼
Audit Layer
â”‚
â–¼
Pytest Validation

```

---

## ğŸ“‚ Project Structure

```

retail-etl-platform/
â”‚
â”œâ”€â”€ etl_core/
â”‚   â”œâ”€â”€ extraction/        # Source extraction logic
â”‚   â”œâ”€â”€ transformations/   # Incremental & transformation logic
â”‚   â”œâ”€â”€ loading/           # Load into warehouse
â”‚   â”œâ”€â”€ audit/             # Audit logging
â”‚   â””â”€â”€ orchestration/     # Pipeline controller
â”‚
â”œâ”€â”€ etl_tests/
â”‚   â”œâ”€â”€ layer1_source_to_staging/
â”‚   â”œâ”€â”€ layer2_staging_to_transform/
â”‚   â”œâ”€â”€ layer3_transform_to_fact/
â”‚   â”œâ”€â”€ layer4_e2e/
â”‚   â””â”€â”€ layer5_audit/
â”‚
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## ğŸ” ETL Flow Explanation

### 1ï¸âƒ£ Extraction
- Reads data from MySQL source tables
- Uses `pandas.read_sql()`
- Supports table-level extraction

### 2ï¸âƒ£ Incremental Loading
- Uses last processed date from `fact_sales`
- Prevents duplicate loading
- Restart-safe logic

### 3ï¸âƒ£ Transformation
- Aggregation
- Filtering
- Monthly summaries
- Inventory calculations

### 4ï¸âƒ£ Loading
Data is loaded into:
- `fact_sales`
- `inventory_levels_by_store`
- `monthly_sales_summary`

---

## ğŸ§¾ Audit Framework

Two audit tables are maintained:

### ğŸ”¹ etl_run_audit
Tracks overall pipeline execution

| Column | Description |
|------|-------------|
| run_id | ETL run identifier |
| pipeline_name | Name of pipeline |
| status | SUCCESS / FAILED |
| start_time | Execution start |
| end_time | Execution end |
| total_tables_loaded | Count |
| total_rows_loaded | Count |
| error_message | Failure reason |

### ğŸ”¹ table_load_audit
Tracks table-level execution

| Column | Description |
|------|-------------|
| run_id | FK to etl_run_audit |
| table_name | Table name |
| rows_loaded | Rows processed |
| status | SUCCESS / FAILED |
| error_message | Optional |

---

## ğŸ§ª Testing Strategy

### âœ” Layer-wise Tests
| Layer | Purpose |
|------|--------|
| Layer 1 | Source validation |
| Layer 2 | Transformation validation |
| Layer 3 | Fact table validation |
| Layer 4 | End-to-end testing |
| Layer 5 | Audit verification |

### âœ” Audit Tests Validate
- ETL execution success
- Table-level audit entries
- Row counts
- Run-to-table mapping
- Failure handling

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
````

### 2ï¸âƒ£ Run ETL Pipeline

```bash
python -m etl_core.orchestration.pipeline
```

### 3ï¸âƒ£ Run All Tests

```bash
pytest -v
```

### 4ï¸âƒ£ Run Only Audit Tests

```bash
pytest etl_tests/layer5_audit -v
```

---

## ğŸ§  Key Features

âœ” Incremental data loading
âœ” Audit-driven ETL design
âœ” Restart-safe execution
âœ” Pytest-based validation
âœ” Production-ready architecture
âœ” Clean Git workflow

---

## ğŸš€ Future Enhancements

* GitHub Actions CI/CD
* SQLAlchemy-based connection layer
* Data quality checks
* Airflow orchestration
* Dockerized deployment

---

## ğŸ‘¤ Author

**Shrilekh Shrikhande**
ETL / Data Engineering Enthusiast
ğŸ“ India

---

